{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP Compressed Sensing for MR Images\n",
    "\n",
    "Diana Mateus\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Participants: JAMOUD YASSINE LA DEBROUILLE, SAMY HAFFOUDHII LE NERVEUX, SAAD COSA SPORTA ALAOUI AZIZ DU SU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GOAL\n",
    "This notebook explores one of the most useful applications of compressed sensing, namely Magnetic Resonance Image (MRI) reconstruction. \n",
    "\n",
    "We will use the SigPy module, and this notebook is partly inspired on the module's tutorial. \n",
    "\n",
    "There will two datasets to explore:\n",
    "\n",
    "- The first is a controlled dataset for which we have a ground truth digital **phantom** image.\n",
    "- The second is a multi-channel data from the ISMRM reproducible challenge (Source: Martin Uecker). The dataset contains k-space measurements of an **in-vivo brain** scan acquired with a projection reconstruction trajectory. \n",
    "\n",
    "\n",
    "### References\n",
    "\n",
    "You can refer to the next links to search the answer of some of the questions\n",
    "\n",
    "- An old but very useful site about the MR Imaging is https://www.mr-tip.com, here you will find definitions of all the MRI specific terms, the parallel acquisition and also of some of the methods. \n",
    "\n",
    "- A complete website about MRI in questions and answers http://mriquestions.com/complete-list-of-questions.html \n",
    "\n",
    "- The original scientific papers regarding the new methods (other than classical inv problems algorithms)\n",
    "\n",
    "    - [Sense](https://www.physast.uga.edu/classes/phys8900/qzhao/PDF8500_08/SENSE.pdf)\n",
    "    - [Espirit](https://onlinelibrary.wiley.com/doi/pdf/10.1002/mrm.24751)\n",
    "    \n",
    "- [SigPy documentation](https://sigpy.readthedocs.io) \n",
    "\n",
    "- Do not hesitate to find and cite your own sources (papers, blogs, tutorials or videos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requirements\n",
    "Install the required module Sigpy and load modules and functions\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sigpy as sp\n",
    "import sigpy.plot as pl\n",
    "import matplotlib.pyplot as plt\n",
    "from math import log10, sqrt \n",
    "from sigpy.mri import poisson, spiral,radial\n",
    "import sigpy.mri as mr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiChannelPhantomKspace(shape =(256,256), nchannels=1):\n",
    "\n",
    "    #loading the logan phantom\n",
    "    logan = sp.shepp_logan(shape)\n",
    "\n",
    "    #copying the fft of the phantom on the different channels\n",
    "    logan_multi = np.zeros((nchannels,shape[0],shape[1]),dtype=np.complex_)\n",
    "    logan_multi_ksp = np.zeros((nchannels,shape[0],shape[1]),dtype=np.complex_)\n",
    "    ksp = sp.fft(logan)\n",
    "    \n",
    "    for i in range(nchannels):\n",
    "        logan_multi[i,:,:]= logan\n",
    "        logan_multi_ksp[i,:,:]= ksp\n",
    "    return logan_multi_ksp\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PSNR(original, compressed): \n",
    "    mse = np.mean((original - compressed) ** 2) \n",
    "    if(mse == 0):    #  MSE is zero means no noise is present in the signal . \n",
    "        return -100  #  Therefore PSNR is irrelevant\n",
    "    max_pixel = original.max()\n",
    "    psnr = 20 * log10(max_pixel / sqrt(mse))\n",
    "    return psnr "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REPORT INSTRUCTIONS\n",
    "\n",
    "Prepare a report following the **structure bellow** and answering to the questions **with your own words**\n",
    "\n",
    "**Hint:** To answer some of the questions you will need to look within the references provided above: ``MRI Questions website`` (e.g. section K-space), you can also search for keywords (e.g. sensitivity, ESPIRIT) within the ``MRI-tip website``\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Visualizing and preparing the datasets\n",
    "\n",
    "#### 1.1.  K-space:\n",
    "\n",
    "a) Visualize the **phantom** dataset with a single channel. \n",
    "\n",
    "b) Visualize the **invivo brain** dataset with multiple channels.\n",
    "\n",
    "c) What do the images show? What do the values in the K-Space stand for?\n",
    "     \n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and display the k-space data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load phantom data\n",
    "\n",
    "ksp_phantom = multiChannelPhantomKspace(nchannels=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "\n",
    "pl.ImagePlot(np.log(np.abs(ksp_phantom)+1e-16), z=0, title='Logan Phantom')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the in-vivo data\n",
    "ksp = np.load('cartesian_ksp.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the invivo data\n",
    "plt.rcParams[\"figure.figsize\"] = (10,5)\n",
    "\n",
    "# Fill in\n",
    "pl.ImagePlot(np.log(np.abs(ksp)+1e-16), z=0, title='Cartesian KSP')\n",
    "\n",
    "sample_invivo = np.abs(ksp[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On observe les signaux bruts fournis par la machine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  2. Reconstruction of the full phantom data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Reconstruction of the full phantom data\n",
    "\n",
    "**2.1.** How do we reconstruct the MRI data from a single fully sampled k-space? \n",
    "    \n",
    "**2.2.** Implement and show the results of reconstructing the **phantom** image from the fully sampled data\n",
    "    \n",
    "**2.3.** Compute the wavelet transform of the fully reconstructed image. Why is the wavelet transform a good choice for CS? demonstrate by showing the histogram of the wavelet coefficients ordered from the largest to the smallest.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Direct reconstruction from full data\n",
    "\n",
    "Hint: use sigpy ifft with axes=(-1, -2), axis=0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_recons = np.abs(sp.ifft(ksp_phantom, axes=(-1,-2)))[0]\n",
    "\n",
    "plt.imshow(image_recons, cmap='gray')\n",
    "plt.title('Reconstructed image')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Wavelet transform \n",
    "\n",
    "Hint: use sigpy fwt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fwt = sp.fwt(image_recons)\n",
    "fwt_log = np.log(np.abs(ksp_fwt) + 10**-12)\n",
    "\n",
    "pl.ImagePlot(fwt_log, title='Wavelet transform of the reconstructed image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fwt = fwt.flatten()\n",
    "fwt_sorted = sorted(abs(fwt))[::-1]\n",
    "\n",
    "plt.hist(fwt_sorted, bins=256)\n",
    "plt.title('Histogramme des coefficients de la FWT')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Compressed Sensing on phantom data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Reconstruction from a sampled dataset (phantom)\n",
    "\n",
    "In the next steps we will simulating a compressed sensing  acquisition by sampling the k-space, then reconstruct the image from the sampled data\n",
    "    \n",
    "**3.1.** Look at the example code to generate sampling masks, apply the mask to the **phantom data** and show the resultant k-space. What changes when we modify the acceleration rate or the calibration shape? \n",
    "\n",
    "**3.2.** Create a sampled phantom dataset by applying a sampling mask created with an acceleration of 6 and a calibration shape of 20.\n",
    "    \n",
    "**3.3.** **Reconstruction from sampled data:**  Reconstruct the MR image with the direct method (ifft) considering non sampled coefficients to be zero. What do you observe?\n",
    "\n",
    "**3.4.** Use the **Wavelets + L1** method from the sigpy mri.apps to reconstruct the **sampled** phantom dataset. What is the criteria being optimized?\n",
    "\n",
    "\n",
    "**3.5.** Find the optimal lambda parameter by trial-and-error, choosing the value of lambda that maximizes the PSNR with respect to the fully sampled data. \n",
    "\n",
    "**3.6.** Discuss how the reconstruction from the full dataset compares to the sampled dataset\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code example for  generating masks \n",
    "\n",
    "Hint: use the poisson sampling function from sigpy https://sigpy.readthedocs.io/en/latest/generated/sigpy.mri.poisson.html#sigpy.mri.poisson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example sampling for a single accelerating factor\n",
    "\n",
    "acc=(6) #Float Target acceleration factor. Must be greater than 1.\n",
    "shape_calib=20 # Size of the calibration window.\n",
    "shape_z=ksp_phantom.shape[1]\n",
    "shape_y=ksp_phantom.shape[2]\n",
    "\n",
    "random_seed = 42\n",
    "file_name = './mask_logan_r%0.2g_c%d.npy' % (acc, shape_calib)\n",
    "print('Creating mask (%s)...' % file_name)\n",
    "\n",
    "mask = poisson(img_shape=[shape_z, shape_y], accel=acc, \n",
    "               max_attempts =15, tol=0.5, \n",
    "               calib=(shape_calib, shape_calib))\n",
    "\n",
    "print(mask.shape)\n",
    "print(mask.dtype)\n",
    "\n",
    "np.save(file_name, mask.astype(np.complex64))\n",
    "\n",
    "plt.imshow(np.abs(np.real(mask)),cmap='gray')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Direct Reconstruction from sampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ksp_phantom_masked = ksp_phantom * mask\n",
    "\n",
    "pl.ImagePlot(np.log(np.abs(ksp_phantom_masked)+1e-16), z=0, title='Logan Phantom')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_recons = np.sum(np.abs(sp.ifft(ksp_phantom_masked, axes=(-1,-2)))**2,axis=0)**0.5\n",
    "\n",
    "plt.imshow(image_recons, cmap='gray')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  L1 and Wavelet reconstructions of phantom data\n",
    "Hint: Use the optimization apps  https://sigpy.readthedocs.io/en/latest/mri_app.html\n",
    "\n",
    "To run an App, you simply do `app.run()`. You should be able to see a progress bar showing the `App`'s progress. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mps_phantom = np.ones((1, 256, 256))\n",
    "alpha = 1\n",
    "wavelet_recons = sp.mri.app.L1WaveletRecon(ksp_phantom,mps_phantom,alpha)\n",
    "img_recons = wavelet_recons.run()\n",
    "\n",
    "plt.imshow(np.abs(img_recons), cmap='gray')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lamda = (0.00005, 0.0005, 0.005,0.5, 5, 50, 500, 5000)\n",
    "plt.rcParams[\"figure.figsize\"] = (15,7)\n",
    "\n",
    "for i, l in enumerate(lamda):\n",
    "    wavelet_recons = sp.mri.app.L1WaveletRecon(ksp_phantom,mps_phantom,l)\n",
    "    img_recons = wavelet_recons.run()\n",
    "    plt.subplot(2, 4, i + 1)\n",
    "    plt.imshow(np.abs(img_recons), cmap='gray')\n",
    "    plt.title(f\"lambda = {l}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Compressed Sensing on invivo/brain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. **Compressed sensing** of the in-vivo brain dataset\n",
    "\n",
    "For the invivo brain dataset we only have access to the sampled data (no full acquisition). However, different to the phantom, this dataset is multi-parallel and can make use of sensitivity maps for reconstruction.\n",
    "\n",
    "\n",
    "**4.1.** Reconstruct the MR image using the direct reconstruction for each channel. What do you observe? \n",
    "\n",
    "\n",
    "**4.2.** Single reconstruction from a mutiparallel acquisition\n",
    "\n",
    "   a) Describe how multiparallel MRI data differs from traditional MRI?\n",
    "   \n",
    "   b) Use the **Root-Sum-of-Squares reconstruction (RSS)** to recover a single MR image from the multichannel and sampled dataset. Consider the non sampled coefficients to be zero. \n",
    "\n",
    "$$\n",
    "    I_{\\rm RSS} = \n",
    "    \\sqrt{\n",
    "    \\sum_{n=1}^{N {\\rm channels}} IFFT(ksp)^2\n",
    "    }\n",
    "$$\n",
    "\n",
    "       \n",
    "**4.3.** Reconstruction with **sensitivity maps**\n",
    "\n",
    "   a) What is a sensitivity map?, what are sensitivity maps useful for?\n",
    "\n",
    "   b) Compute and display the **sensitivity maps** for the in-vivo brain dataset using the ESPIRIT app from sigpy. What do you observe?\n",
    "\n",
    "   c) Use the mri.apps to do the reconstruction of the **brain dataset** using the SENSE method using the computed sensitivity maps\n",
    "  \n",
    "   d) Look at the documentation, what criteria is being optimized here?\n",
    "   \n",
    "   e) Change the regularization parameters of each method and discuss how they change the qualitative results\n",
    "\n",
    "\n",
    "**4.4.** **Regularized reconstructions**\n",
    "\n",
    "   a) Use the mri.apps to do the reconstruction of the **brain dataset** using the following methods\n",
    "        - Wavelet L1 Reconstruction\n",
    "        - Total Variation Reconstruction\n",
    "        \n",
    "   b) Look at the documentation of each method and explain the problem solved in each case. \n",
    "   \n",
    "   c) Change the regularization parameters of each method and discuss how they change the qualitative results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(8):\n",
    "    image_recons = np.abs(sp.ifft(ksp[i], axes=(-1,-2)))**0.5\n",
    "    \n",
    "    plt.subplot(2, 4, i + 1)\n",
    "    plt.title(f'Channel {i + 1}')\n",
    "    plt.imshow(image_recons, cmap='gray')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ksp_ifft = sp.ifft(ksp, axes=(-1, -2))\n",
    "image_recons = np.sum(np.abs(ksp_ifft), axis=0) ** 0.5\n",
    "\n",
    "plt.imshow(image_recons, cmap='gray')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sensitivity maps\n",
    "\n",
    "To perform parallel imaging reconstruction of the multi-parallel data, we will use the ESPIRiT method to estimate first the sensitivity maps. To do this, we can use the [EspiritCalib](https://sigpy.readthedocs.io/en/latest/generated/sigpy.mri.app.EspiritCalib.html#sigpy.mri.app.EspiritCalib) App from sigpy.\n",
    "\n",
    "To run an App, you simply do `app.run()`. You should be able to see a progress bar showing the `App`'s progress. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sensitivity maps\n",
    "\n",
    "mps_phantom = mr.app.EspiritCalib(ksp_phantom).run()\n",
    "\n",
    "mps = mr.app.EspiritCalib(ksp).run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.ImagePlot( mps_phantom, title=\"Log Phantom\" )\n",
    "plt.show()\n",
    "\n",
    "pl.ImagePlot( mps, z=0, title=\"Log Phantom\" )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reconstructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint: Use the optimization apps  https://sigpy.readthedocs.io/en/latest/mri_app.html\n",
    "\n",
    "To run an App, you simply do `app.run()`. You should be able to see a progress bar showing the `App`'s progress. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_ = 0.01\n",
    "\n",
    "image_recons = mr.app.SenseRecon(ksp, mps, lambda_).run()\n",
    "\n",
    "pl.ImagePlot(image_recons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_ = 0.01\n",
    "\n",
    "image_recons = mr.app.L1WaveletRecon(ksp, mps, lambda_).run()\n",
    "\n",
    "pl.ImagePlot(image_recons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_ = 0.01\n",
    "\n",
    "image_recons = mr.app.TotalVariationRecon(ksp, mps, lambda_).run()\n",
    "\n",
    "pl.ImagePlot(image_recons)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
