{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP3 - Frequency Domain\n",
    "ATRIM - Option Datasim\n",
    "\n",
    "Ecole Centrale Nantes\n",
    "\n",
    "Diana Mateus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Participants: Yassine Jamoud, Samy Haffoudhi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GOAL\n",
    "\n",
    "In this lab we will:\n",
    "- put into practice the computation of the DFT of an image, and learn to interpret the result. \n",
    "- Design and apply bandpass and Notch filters. \n",
    "- Replicate the use of the DCT for image compression in Jpeg.\n",
    "\n",
    "## 0. Preparation \n",
    "\n",
    "### 0.1 Import the required modules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import ndimage\n",
    "from scipy import misc\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import skimage.io as io\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.2 Define the main image folder\n",
    "Make sure the subsequent parts of this notebook refer to this definition IMDIR. **When evaluating your notebook I should only need to change the path here** to run the entire notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMDIR = \"./images/\"\n",
    "print(os.listdir(IMDIR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. The Discrete Fourier Transform\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In the report:** Resume the steps and explain the DFTs for each image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Computing and visualizing the DFT  \n",
    "\n",
    "\n",
    "In this exercise we will compute and visualize a DFT using numpy's fft functions:\n",
    "- ```np.fft.fft2```: computes the two-dimensional FFT of an image.\n",
    "- ```np.fft.fftshift```: center the frecuencies in the middle of the image\n",
    "- ```np.fft.ifftshift```: reverses the centering\n",
    "- ```np.fft.ifft2```: inverse fourier transform\n",
    "- ```np.real```: takes the real components of a complex number\n",
    "- ```np.abs```: recovers the magnitude of a complex number\n",
    "- ```np.angle```: recovers the phase of a complex number \n",
    "- ```np.log```: computes the logarithm\n",
    "\n",
    "Apply the functions above to the images in the ```Fourier``` folder. Display in a single row for each image:\n",
    "\n",
    "**a)** the original image \n",
    "\n",
    "**b)** the magnitude of its fft (scaled logarithmically)\n",
    "\n",
    "**c)** the magnitude of its **centered(shifted)** fft (scaled logarithmically)\n",
    "\n",
    "**c)** the inverse fft of the above transformed image (all the steps shouls be reversed)\n",
    "\n",
    "**d) For each image explain how the information in the image relates to its representation in the frequency domain**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBDIR = os.path.join(IMDIR, \"Fourier\")\n",
    "\n",
    "\n",
    "for root, dirnames, filenames in os.walk(SUBDIR):\n",
    "    # print path to all filenames.\n",
    "    for filename in filenames:\n",
    "        f = os.path.join(root, filename)\n",
    "        if f.endswith(('.png', '.jpg', '.jpeg','.JPG', '.tif', '.gif')):\n",
    "            im = io.imread(f,as_gray=True)\n",
    "            #im = resize(im,(100,100),mode='constant') # RESIZE IF TOO SLOW \n",
    "    \n",
    "            im_fft = np.fft.fft2(im)\n",
    "            im_fft_centered = np.fft.fftshift(im_fft)\n",
    "            \n",
    "            im_ftt_not_centered = np.fft.ifftshift(im_fft_centered)\n",
    "            im_inverse_fft = np.fft.ifft2(im_ftt_not_centered)\n",
    "            image_recovered = np.real(im_inverse_fft)\n",
    "            \n",
    "            fig=plt.figure(figsize=(16, 18))\n",
    "\n",
    "            plt.subplot(141)\n",
    "            plt.title('Original image')\n",
    "            plt.imshow(im)\n",
    "            plt.gray()\n",
    "            plt.axis('off')\n",
    "            \n",
    "            plt.subplot(142)\n",
    "            plt.title('log FFT ')\n",
    "            plt.imshow(np.log(np.abs(im_fft)))\n",
    "            plt.gray()\n",
    "            plt.axis('off')\n",
    "            \n",
    "            plt.subplot(143)\n",
    "            plt.title('log centered FFT ')\n",
    "            plt.imshow(np.log(np.abs(im_fft_centered)))\n",
    "            plt.gray()\n",
    "            plt.axis('off')\n",
    "\n",
    "            plt.subplot(144)\n",
    "            plt.title('Reconstructed image')\n",
    "            plt.imshow(image_recovered)\n",
    "            plt.gray()\n",
    "            plt.axis('off')\n",
    "            \n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commentaires pour chaque image (dans l'ordre) :\n",
    "\n",
    "* la strucutre de l'image (motifs carrés repetées) se refléte dans sa transformées de Fourier\n",
    "* les rayures sont refletées dans la transformée de Fourier avec par exemple les pics selon les axes horizontaux et verticaux correspondant aux rayures horizontales et verticales. Ces pics sont à plus ou moins haute fréquence selon l'espacement entre les rayures\n",
    "* Ici la transformée comporte majoritairement une ligne verticale correspondant au pattern régulier des pavés dans l'image\n",
    "* La transformée comporte 2 lignes verticales et horizontales et principales correspondant à la strucutre régulière de l'image, le reste correspond principalement au cercle visible en haut à droite de l'image\n",
    "* Encore une fois la strucutre régulière du fond se manifeste dans la transformée de Fourier, on peut aussi voir des diagonales correspondant aux rayures du zebre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Filtering in the frequency domain\n",
    "**a)** Implement two functions that create a low pass and a high-pass filter frequency space for a given cutoff frequency $D_0$. The functions receive as input parameter the type of filter: 'ideal' or 'gaussian', and the filter parameters.\n",
    "\n",
    "**b)** Show the filter frequency responses for different values of the cuttoff frequency both for the gaussian and the ideal filters. \n",
    "\n",
    "**c)** Filter **ONE** of the images in the ```freqfilt``` folder with the implemented functions. \n",
    "\n",
    "**d)** For the image in c) Show the results of the low and high pass filters  both in the frequency and the spatial domain.\n",
    "\n",
    "**e)** Show and compare the results from the ideal and the Gaussian filter. \n",
    "**Question**: Are there any observable differences? (write answers in the ANSWERS block below)\n",
    "\n",
    "**f)** **Question**: What happens with the DC component after a highpass filter has been applied?\n",
    "\n",
    "**g)** Design and apply the right filter to do the following tasks:\n",
    "- remove the noise of ```tower.jpg```\n",
    "- smooth out the freckles of trying to keep the face sharp ```face1.jpg```\n",
    "- remove out the moire pattern from  ```car-moire-pattern.tif```\n",
    "- highlight the wrinkles of ```face2.jpg```\n",
    "- remove the interference pattern of ```astronaut-interference.tif```\n",
    "- remove the shadow from the ```text-spotshade.tif```\n",
    "\n",
    "**Explain** the filter choice, show the spatial and frequency response and comment your findings.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IN THE REPORT** Answer questions e), f) and g) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lowpass_filter(D, shape, filter_type='ideal'):\n",
    "    Q, P = shape\n",
    "    if filter_type == 'ideal':\n",
    "        lowpass = np.array([[int((u - P//2)**2 + (v - Q//2)**2 < D**2) for u in range(P)] for v in range(Q)])\n",
    "    else:\n",
    "        lowpass = np.array([[ np.exp(-((u - P//2)**2 + (v - Q//2)**2 )/(2*D**2)) for u in range(P)]for v in range(Q)])\n",
    "    return lowpass\n",
    "\n",
    "def highpass_filter(D,shape,filter_type='ideal'):\n",
    "    Q, P = shape\n",
    "    if filter_type == 'ideal':\n",
    "        lowpass = np.array([[int((u - P//2)**2 + (v - Q//2)**2 > D**2) for u in range(P)] for v in range(Q)])\n",
    "    else:\n",
    "        lowpass = 1-lowpass_filter(D,shape,'gaussian')\n",
    "    return lowpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(5, 9))\n",
    "\n",
    "D_values = [3, 10, 15]\n",
    "\n",
    "counter = 1\n",
    "\n",
    "for D in D_values:\n",
    "    f_ideal = lowpass_filter(D, (40, 40))\n",
    "    f_gauss = lowpass_filter(D, (40, 40), 'gauss')\n",
    "    \n",
    "    plt.subplot(3,2,counter)\n",
    "    plt.imshow(f_ideal, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.title(f'Ideal D = {D}')\n",
    "    \n",
    "    plt.subplot(3,2,counter+1)\n",
    "    plt.imshow(f_gauss, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.title(f'Gauss D = {D}')\n",
    "    \n",
    "    counter += 2\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBDIR = os.path.join(IMDIR, \"Frequency\")\n",
    "f = os.path.join(SUBDIR, \"face2.jpg\")\n",
    "\n",
    "im = io.imread(f, as_gray=True)\n",
    "im = im.astype(float)\n",
    "\n",
    "N,M = im.shape\n",
    "pad_im = np.zeros((2*N,2*M))\n",
    "pad_im[0:N,0:M] = im\n",
    "\n",
    "fft = np.fft.fft2(pad_im)\n",
    "\n",
    "fft_center = np.fft.fftshift(fft)\n",
    "\n",
    "D=20\n",
    "high = highpass_filter(D,pad_im.shape);\n",
    "low = lowpass_filter(D,pad_im.shape);\n",
    "high_gauss = highpass_filter(D,pad_im.shape, 'gaussian')\n",
    "low_gauss = lowpass_filter(D,pad_im.shape,'gaussian');\n",
    "\n",
    "fft_low = low * fft_center;\n",
    "fft_high = high * fft_center;\n",
    "fft_low_gauss = low_gauss * fft_center;\n",
    "fft_high_gauss = high_gauss * fft_center\n",
    "\n",
    "inverse_fft_low = np.fft.ifftshift(fft_low)\n",
    "inverse_fft_high = np.fft.ifftshift(fft_high)\n",
    "inverse_fft_low_gauss = np.fft.ifftshift(fft_low_gauss)\n",
    "inverse_fft_high_gauss = np.fft.ifftshift(fft_high_gauss)\n",
    "    \n",
    "inverse_fft_low = np.fft.ifft2(inverse_fft_low)\n",
    "inverse_fft_high = np.fft.ifft2(inverse_fft_high)\n",
    "inverse_fft_low_gauss = np.fft.ifft2(inverse_fft_low_gauss)\n",
    "inverse_fft_high_gauss = np.fft.ifft2(inverse_fft_high_gauss)\n",
    "\n",
    "im_low = np.real(inverse_fft_low)\n",
    "im_high = np.real(inverse_fft_high)\n",
    "im_low_gauss = np.real(inverse_fft_low_gauss)\n",
    "im_high_gauss = np.real(inverse_fft_high_gauss)\n",
    "\n",
    "final_low = im_low[:N,:M]\n",
    "final_high = im_high[:N,:M]\n",
    "final_low_gauss = im_low_gauss[:N,:M]\n",
    "final_high_gauss = im_high_gauss[:N,:M]\n",
    "\n",
    "fig=plt.figure(figsize=(16, 8))\n",
    "\n",
    "plt.subplot(2,5,1)\n",
    "plt.imshow(im, cmap = 'gray')\n",
    "plt.axis('off')\n",
    "plt.title('Original')\n",
    "\n",
    "plt.subplot(2,5,2)\n",
    "plt.imshow(final_low, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title('Low Pass Ideal')\n",
    "\n",
    "plt.subplot(2,5,3)\n",
    "plt.imshow(final_high, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title('High Pass Ideal')\n",
    "\n",
    "plt.subplot(2,5,4)\n",
    "plt.imshow(final_low_gauss, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title('Low Pass Gauss')\n",
    "\n",
    "plt.subplot(2,5,5)\n",
    "plt.imshow(final_high_gauss, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title('High Pass Gauss')\n",
    "\n",
    "plt.subplot(2,5,6)\n",
    "plt.imshow(np.log(np.abs(fft_center)), cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title('Original')\n",
    "\n",
    "plt.subplot(2,5,7)\n",
    "plt.imshow(np.log(np.abs(np.fft.fftshift(np.fft.fft2(final_low)))), cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title('Low Pass Ideal')\n",
    "\n",
    "plt.subplot(2,5,8)\n",
    "plt.imshow(np.log(np.abs(np.fft.fftshift(np.fft.fft2(final_high)))), cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title('High Pass Ideal')\n",
    "\n",
    "plt.subplot(2,5,9)\n",
    "plt.imshow(np.log(np.abs(np.fft.fftshift(np.fft.fft2(final_low_gauss)))), cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title('Low Pass Gauss')\n",
    "\n",
    "plt.subplot(2,5,10)\n",
    "plt.imshow(np.log(np.abs(np.fft.fftshift(np.fft.fft2(final_high_gauss)))), cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title('High Pass Gauss')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Nous observons alors à l'aide des différentes images ci-dessus que les filtres Gaussiens permettent bien d'éliminer les artefacts sur l'image, par exemple les lignes verticales sur le côté gauche du visage. Ils sont dus aux variation brusques de la fonction de transfert, le filtre gaussien permet de remédier à ce problème.\n",
    "* Après application d'un filtre passe haut la composante continue est supprimée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_filter(im, f):\n",
    "    N, M = im.shape\n",
    "    im_padded = np.zeros((2*N, 2*M))\n",
    "    im_padded[0:N,0:M] = im\n",
    "    im_fft = np.fft.fft2(im_padded)\n",
    "    im_fft = np.fft.fftshift(im_fft)\n",
    "    res_fft = f * im_fft\n",
    "    res = np.fft.ifft2(np.fft.ifftshift(res_fft))\n",
    "    res = np.real(res)\n",
    "    res = res[:N, :M]\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBDIR = os.path.join(IMDIR, \"Frequency\")\n",
    "fig = plt.figure(figsize=(30, 36))\n",
    "\n",
    "# tower\n",
    "\n",
    "f = os.path.join(SUBDIR, \"tower.jpg\")\n",
    "im = io.imread(f, as_gray=True)\n",
    "im = im.astype(float)\n",
    "\n",
    "H, W = im.shape\n",
    "f_denoise = np.ones((2*H, 2*W)) # à remplacer par le filtre adapté\n",
    "res = apply_filter(im, f_denoise)\n",
    "\n",
    "plt.subplot(6,4,1)\n",
    "plt.imshow(im, cmap = 'gray')\n",
    "plt.axis('off')\n",
    "plt.title('Original')\n",
    "\n",
    "plt.subplot(6,4,2)\n",
    "plt.imshow(res, cmap = 'gray')\n",
    "plt.axis('off')\n",
    "plt.title('Filtered Spatial')\n",
    "\n",
    "plt.subplot(6,4,3)\n",
    "plt.imshow(res, cmap = 'gray')\n",
    "plt.imshow(np.log(np.abs(np.fft.fftshift(np.fft.fft2(im)))), cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title('Original Frequency')\n",
    "\n",
    "plt.subplot(6,4,4)\n",
    "plt.imshow(res, cmap = 'gray')\n",
    "plt.imshow(np.log(np.abs(np.fft.fftshift(np.fft.fft2(res)))), cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title('Filtered Frequency')\n",
    "\n",
    "# face 1\n",
    "\n",
    "f = os.path.join(SUBDIR, \"face1.jpg\")\n",
    "im = io.imread(f, as_gray=True)\n",
    "im = im.astype(float)\n",
    "\n",
    "H, W = im.shape\n",
    "f_denoise = lowpass_filter(80, (2*H, 2*W), 'gauss')\n",
    "res = apply_filter(im, f_denoise)\n",
    "\n",
    "plt.subplot(6,4,5)\n",
    "plt.imshow(im, cmap = 'gray')\n",
    "plt.axis('off')\n",
    "plt.title('Original')\n",
    "\n",
    "plt.subplot(6,4,6)\n",
    "plt.imshow(res, cmap = 'gray')\n",
    "plt.axis('off')\n",
    "plt.title('Filtered Spatial')\n",
    "\n",
    "plt.subplot(6,4,7)\n",
    "plt.imshow(res, cmap = 'gray')\n",
    "plt.imshow(np.log(np.abs(np.fft.fftshift(np.fft.fft2(im)))), cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title('Original Frequency')\n",
    "\n",
    "plt.subplot(6,4,8)\n",
    "plt.imshow(res, cmap = 'gray')\n",
    "plt.imshow(np.log(np.abs(np.fft.fftshift(np.fft.fft2(res)))), cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title('Filtered Frequency')\n",
    "\n",
    "# face 2\n",
    "\n",
    "f = os.path.join(SUBDIR, \"face2.jpg\")\n",
    "im = io.imread(f, as_gray=True)\n",
    "im = im.astype(float)\n",
    "\n",
    "H, W = im.shape\n",
    "f_denoise = lowpass_filter(60, (2*H, 2*W))\n",
    "res = apply_filter(im, f_denoise)\n",
    "\n",
    "plt.subplot(6,4,9)\n",
    "plt.imshow(im, cmap = 'gray')\n",
    "plt.axis('off')\n",
    "plt.title('Original')\n",
    "\n",
    "plt.subplot(6,4,10)\n",
    "plt.imshow(res, cmap = 'gray')\n",
    "plt.axis('off')\n",
    "plt.title('Filtered Spatial')\n",
    "\n",
    "plt.subplot(6,4,11)\n",
    "plt.imshow(res, cmap = 'gray')\n",
    "plt.imshow(np.log(np.abs(np.fft.fftshift(np.fft.fft2(im)))), cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title('Original Frequency')\n",
    "\n",
    "plt.subplot(6,4,12)\n",
    "plt.imshow(res, cmap = 'gray')\n",
    "plt.imshow(np.log(np.abs(np.fft.fftshift(np.fft.fft2(res)))), cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title('Filtered Frequency')\n",
    "\n",
    "# Astronaut\n",
    "\n",
    "f = os.path.join(SUBDIR, \"astronaut-interference.tif\")\n",
    "im = io.imread(f, as_gray=True)\n",
    "im = im.astype(float)\n",
    "\n",
    "H, W = im.shape\n",
    "f_denoise = np.ones((2 * H, 2 * W))\n",
    "res = apply_filter(im, f_denoise)\n",
    "\n",
    "plt.subplot(6,4,13)\n",
    "plt.imshow(im, cmap = 'gray')\n",
    "plt.axis('off')\n",
    "plt.title('Original')\n",
    "\n",
    "plt.subplot(6,4,14)\n",
    "plt.imshow(res, cmap = 'gray')\n",
    "plt.axis('off')\n",
    "plt.title('Filtered Spatial')\n",
    "\n",
    "plt.subplot(6,4,15)\n",
    "plt.imshow(res, cmap = 'gray')\n",
    "plt.imshow(np.log(np.abs(np.fft.fftshift(np.fft.fft2(im)))), cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title('Original Frequency')\n",
    "\n",
    "plt.subplot(6,4,16)\n",
    "plt.imshow(res, cmap = 'gray')\n",
    "plt.imshow(np.log(np.abs(np.fft.fftshift(np.fft.fft2(res)))), cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title('Filtered Frequency')\n",
    "\n",
    "# Text\n",
    "\n",
    "f = os.path.join(SUBDIR, \"text-spotshade.tif\")\n",
    "im = io.imread(f, as_gray=True)\n",
    "im = im.astype(float)\n",
    "\n",
    "H, W = im.shape\n",
    "f_denoise = np.ones((2 * H, 2 * W))\n",
    "res = apply_filter(im, f_denoise)\n",
    "\n",
    "plt.subplot(6,4,17)\n",
    "plt.imshow(im, cmap = 'gray')\n",
    "plt.axis('off')\n",
    "plt.title('Original')\n",
    "\n",
    "plt.subplot(6,4,18)\n",
    "plt.imshow(res, cmap = 'gray')\n",
    "plt.axis('off')\n",
    "plt.title('Filtered Spatial')\n",
    "\n",
    "plt.subplot(6,4,19)\n",
    "plt.imshow(res, cmap = 'gray')\n",
    "plt.imshow(np.log(np.abs(np.fft.fftshift(np.fft.fft2(im)))), cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title('Original Frequency')\n",
    "\n",
    "plt.subplot(6,4,20)\n",
    "plt.imshow(res, cmap = 'gray')\n",
    "plt.imshow(np.log(np.abs(np.fft.fftshift(np.fft.fft2(res)))), cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title('Filtered Frequency')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour chaque image dont nous souhaitons enlever le bruit, nous recherchons sur la transformée de Fourier les composantes responsables du bruit et nous concevons un filtre ayant pour effet d'annuler ces composantes. Nous ne sommes cependant pas parvenu à obtenir des résultats satisfaisant en pratique et nous avons alors juste conservé la structure dans code dans la cell ci-dessus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  3. Towards JPEG Compression\n",
    "\n",
    "**Introduction**\n",
    "\n",
    "One of the crucial steps of JPEG Compression is the quantization in frequency space. The procedure follows the next steps:\n",
    "\n",
    "**i)** An image is first subdivided in 8x8 subblocks (assuming the original image has sides whose length is a multiple of 8, if it is not the case just resize it).\n",
    "\n",
    "**ii)** A frequency transformation is computed for each block (computed with a discrete cosine transform DCT II )\n",
    "```\n",
    "fftpack.dct(fftpack.dct(im.T, norm='ortho').T, norm='ortho')\n",
    "```\n",
    "**iii)** The DCT results are then divided by the elements of a predefined quantization matrix, then rounded and stored as integers. **Hint:** use functions  ```round()```, ```astype(np.int32)```\n",
    "\n",
    "**iv)** The result of quantization (which should have many zeros) is then compressed Run Lenght Coding and Huffman coding to reduce the size. The compressed values are saved together with the quantization table.\n",
    "\n",
    "**v)** The reconstruction of the image implies inverting the encoding, the quantization and the dct.\n",
    "\n",
    "See more info in this video.\n",
    "https://www.youtube.com/watch?v=Q2aEzeMDHMA\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What to implement**\n",
    "\n",
    "In this part you will reproduce the steps regarding the DCT from the JPEG compression procedure, that is steps i) to iii). Pick a grayscale image of your choice, resize it if necessary.\n",
    "\n",
    "**a)** Compute the frequency quantization step, using the provided ```quantization_table``` and ``dct_2d`` functions.\n",
    "\n",
    "**b)** Restore the image from its quantized frequency representation.\n",
    "\n",
    "**c)** Show the frequency spectrum  before and after the quantization.\n",
    "\n",
    "**d)** Show:\n",
    "- the original image\n",
    "- the quantized image \n",
    "- the difference between the two.\n",
    "\n",
    "**e)** Repeat the above steps but resizing the input image to 128,128 first. What do you observe ?\n",
    "\n",
    "**f)** Replace the given DCT function by your own basis implementation. Explain any difference.\n",
    "\n",
    "\n",
    "**IN THE REPORT** Comment on your findings for questions d), e) and f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import resize\n",
    "import scipy\n",
    "from scipy import fftpack\n",
    "\n",
    "\n",
    "def dct_2d(im):\n",
    "    return fftpack.dct(fftpack.dct(im.T, norm='ortho').T, norm='ortho')\n",
    "\n",
    "def idct_2d(im):\n",
    "    return fftpack.idct(fftpack.idct(im.T, norm='ortho').T, norm='ortho')\n",
    "\n",
    "def quantization_table(component='lum'):\n",
    "    # Quantization Table for: Photoshop \n",
    "    # (http://www.impulseadventure.com/photo/jpeg-quantization.html)\n",
    "    if component == 'lum':\n",
    "        q = np.array([[2, 2, 2, 2, 3, 4, 5, 6],\n",
    "                      [2, 2, 2, 2, 3, 4, 5, 6],\n",
    "                      [2, 2, 2, 2, 4, 5, 7, 9],\n",
    "                      [2, 2, 2, 4, 5, 7, 9, 12],\n",
    "                      [3, 3, 4, 5, 8, 10, 12, 12],\n",
    "                      [4, 4, 5, 7, 10, 12, 12, 12],\n",
    "                      [5, 5, 7, 9, 12, 12, 12, 12],\n",
    "                      [6, 6, 9, 12, 12, 12, 12, 12]])\n",
    "    elif component == 'chrom':\n",
    "        q = np.array([[3, 3, 5, 9, 13, 15, 15, 15],\n",
    "                      [3, 4, 6, 11, 14, 12, 12, 12],\n",
    "                      [5, 6, 9, 14, 12, 12, 12, 12],\n",
    "                      [9, 11, 14, 12, 12, 12, 12, 12],\n",
    "                      [13, 14, 12, 12, 12, 12, 12, 12],\n",
    "                      [15, 12, 12, 12, 12, 12, 12, 12],\n",
    "                      [15, 12, 12, 12, 12, 12, 12, 12],\n",
    "                      [15, 12, 12, 12, 12, 12, 12, 12]])\n",
    "    else:\n",
    "        raise ValueError((\n",
    "            \"component should be either 'lum' or 'chrom', \"\n",
    "            \"but '{comp}' was found\").format(comp=component))\n",
    "\n",
    "    return q\n",
    "\n",
    "\n",
    "im = scipy.misc.ascent().astype(float)\n",
    "H, W = im.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = quantization_table()\n",
    "quantized = np.zeros((H, W)).astype('int32')\n",
    "\n",
    "# Quantization\n",
    "for i in range(H//8):\n",
    "    for j in range(W//8):\n",
    "        block = im[8*i:8*(i+1), 8*j:8*(j+1)]\n",
    "        block_dct = dct_2d(block)\n",
    "        quantized[8*i:8*(i+1), 8*j:8*(j+1)] = np.round(block_dct / table)\n",
    "        \n",
    "# en pratique pour la phase de compression, on applique maintenant par exemple le Huffman coding\n",
    "\n",
    "# Restoration\n",
    "im_restored = np.zeros((H, W))\n",
    "for i in range(H//8):\n",
    "    for j in range(W//8):\n",
    "        im_restored[8*i:8*(i+1), 8*j:8*(j+1)] = idct_2d(table * quantized[8*i:8*(i+1), 8*j:8*(j+1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 10))\n",
    "\n",
    "plt.subplot(2,3,1)\n",
    "plt.imshow(im, cmap = 'gray')\n",
    "plt.axis('off')\n",
    "plt.title('Original')\n",
    "\n",
    "plt.subplot(2,3,2)\n",
    "plt.imshow(im_restored, cmap = 'gray')\n",
    "plt.axis('off')\n",
    "plt.title('Restored')\n",
    "\n",
    "plt.subplot(2,3,3)\n",
    "plt.imshow(abs(im - im_restored), cmap = 'gray')\n",
    "plt.axis('off')\n",
    "plt.title('Difference')\n",
    "\n",
    "plt.subplot(2,3,4)\n",
    "plt.imshow(np.log(np.abs(np.fft.fftshift(np.fft.fft2(im)))), cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title('Original fft')\n",
    "\n",
    "plt.subplot(2,3,5)\n",
    "plt.imshow(np.log(np.abs(np.fft.fftshift(np.fft.fft2(im_restored)))), cmap = 'gray')\n",
    "plt.axis('off')\n",
    "plt.title('Restored fft')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = resize(im,(128,128),mode='constant')\n",
    "H, W = im.shape\n",
    "\n",
    "quantized = np.zeros((H, W)).astype('int32')\n",
    "\n",
    "# Quantization\n",
    "for i in range(H//8):\n",
    "    for j in range(W//8):\n",
    "        block = im[8*i:8*(i+1), 8*j:8*(j+1)]\n",
    "        block_dct = dct_2d(block)\n",
    "        quantized[8*i:8*(i+1), 8*j:8*(j+1)] = np.round(block_dct / table)\n",
    "\n",
    "# Restoration\n",
    "im_restored = np.zeros((H, W))\n",
    "for i in range(H//8):\n",
    "    for j in range(W//8):\n",
    "        im_restored[8*i:8*(i+1), 8*j:8*(j+1)] = idct_2d(table * quantized[8*i:8*(i+1), 8*j:8*(j+1)])\n",
    "        \n",
    "fig = plt.figure(figsize=(20, 36))\n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(im, cmap = 'gray')\n",
    "plt.axis('off')\n",
    "plt.title('Original')\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(im_restored, cmap = 'gray')\n",
    "plt.axis('off')\n",
    "plt.title('Restored')\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(abs(im - im_restored), cmap = 'gray')\n",
    "plt.axis('off')\n",
    "plt.title('Difference')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque que suite au resizing le bruit semble plus marqué, que ce soit en terme de forme (ce qui était attendu, les pixels étant plus gros) mais également en terme de magnitude puisqu'on peut observer des pixels plus clairs que précedemment ce qui signifie un plus grand écart d'intensité entre les deux images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_T(i, j):\n",
    "    if i == 0:\n",
    "        return 1 / np.sqrt(8)\n",
    "    return np.sqrt(1 / 4) * np.cos((2 * j + 1) * i * np.pi / 16)\n",
    "\n",
    "def dct_matrix():\n",
    "    T = np.array([[get_T(i, j) for j in range(8)] for i in range(8)])\n",
    "    return T\n",
    "\n",
    "def my_dct_2d(im):\n",
    "    T = dct_matrix()\n",
    "    M = im - 128\n",
    "    D = T @ M @ T.T\n",
    "    return D\n",
    "\n",
    "def my_idct_2d(im):\n",
    "    T = dct_matrix()\n",
    "    return np.round(T.T @ im @ T) + 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = scipy.misc.ascent().astype(float)\n",
    "H, W = im.shape\n",
    "\n",
    "quantized = np.zeros((H, W)).astype('int32')\n",
    "\n",
    "# Quantization\n",
    "for i in range(H//8):\n",
    "    for j in range(W//8):\n",
    "        block = im[8*i:8*(i+1), 8*j:8*(j+1)]\n",
    "        block_dct = my_dct_2d(block)\n",
    "        quantized[8*i:8*(i+1), 8*j:8*(j+1)] = np.round(block_dct / table)\n",
    "\n",
    "# Restoration\n",
    "im_restored = np.zeros((H, W))\n",
    "for i in range(H//8):\n",
    "    for j in range(W//8):\n",
    "        im_restored[8*i:8*(i+1), 8*j:8*(j+1)] = my_idct_2d(table * quantized[8*i:8*(i+1), 8*j:8*(j+1)])\n",
    "        \n",
    "fig = plt.figure(figsize=(20, 36))\n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(im, cmap = 'gray')\n",
    "plt.axis('off')\n",
    "plt.title('Original')\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(im_restored, cmap = 'gray')\n",
    "plt.axis('off')\n",
    "plt.title('Restored')\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(abs(im - im_restored), cmap = 'gray')\n",
    "plt.axis('off')\n",
    "plt.title('Difference')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous n'observons pas vraiment de différence significative entre les résultats obtenus avec notre implémentation de dct et celle fournie."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
