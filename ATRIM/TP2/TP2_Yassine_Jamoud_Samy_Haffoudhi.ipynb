{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP2 - Spatial Filtering\n",
    "ATRIM - Option Datasim\n",
    "\n",
    "Ecole Centrale Nantes\n",
    "\n",
    "Diana Mateus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Participants:** Yassine Jamoud, Samy Haffoudhi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GOAL\n",
    "\n",
    "In this lab we will practice the general principles of spatial filtering. Starting from a mean kernel filter we will build up to create and apply Gaussian and derivative filters. Then, we will break the some of the assumptions of linear filtering, when creating a bilinear filtering and looking for Waldo (Charlie)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Preparation\n",
    "\n",
    "* Handling several images can create large memory demands. In order to avoid large size files reuse the image variable names or clear large variables with the command\n",
    "\n",
    "example: ```reset_selective name_variable```\n",
    "\n",
    "* Submit the jupyter notebook empty. To do so, go to the Kernel menu, restart and clear output. \n",
    "\n",
    "* Use always the relative given path for the images\n",
    "\n",
    "* If you get some warnings \"IOPub data rate exceeded\" lauch your notebook with\n",
    "\n",
    "```jupyter notebook --NotebookApp.iopub_data_rate_limit=10000000000```\n",
    "\n",
    "* Resize the images for debugging to accelerate the process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.1 Importing the required modules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.io as io\n",
    "from skimage.transform import resize, rescale\n",
    "from scipy import ndimage\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.2 Define the main image folder\n",
    "Make sure the subsequent parts of this notebook refer to this definition IMDIR. **When evaluating your notebook I should only need to change the path here** to run the entire notebook and find all the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMDIR = \"./images/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Smoothing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.0 Mean Kernel\n",
    "\n",
    "The following ``meanKernel'' function creates an smoothing kernel, which can be used with scipy's \n",
    "```python\n",
    "ndimage.convolve(im,kernel)\n",
    "```\n",
    "convolution function to blur an image.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meanKernel(hs):\n",
    "    kernel = np.zeros((hs*2+1,hs*2+1))\n",
    "    kernel += 1/(hs*2+1)**2\n",
    "    return kernel\n",
    "\n",
    "width=8\n",
    "height=3\n",
    "plt.rcParams['figure.figsize'] = [width, height]\n",
    "\n",
    "#creating and showing three mean kernels of different sizes\n",
    "k = 1\n",
    "for hs in [1,3,11]:\n",
    "    plt.subplot(1,3,k)\n",
    "    kernel = meanKernel(hs)\n",
    "    plt.imshow(kernel, vmin=0, vmax=0.2)\n",
    "    plt.title('Mean')\n",
    "    k+=1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBDIR = os.path.join(IMDIR, \"smooth\")\n",
    "f = os.path.join(SUBDIR, \"grass.jpg\")\n",
    "\n",
    "width=15\n",
    "height=5\n",
    "\n",
    "hs = 3\n",
    "\n",
    "im = io.imread(f, as_gray=True)\n",
    "im = im.astype(float)\n",
    "kernel = meanKernel(hs)\n",
    "im_filtered = ndimage.convolve(im,kernel)\n",
    "# im_filtered = myConvolve(im,kernel)\n",
    "\n",
    "fig=plt.figure(figsize=(width, height))\n",
    "plt.subplot(1,2,1)        \n",
    "plt.imshow(im, cmap = 'gray')\n",
    "plt.title('Gaussian original')\n",
    "        \n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(im_filtered, cmap = 'gray')\n",
    "plt.title('Gaussian conv')\n",
    "            \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Gaussian Kernel\n",
    "Following the above example, create a function that receives the required parameters of a Gaussian kernel (window halfsize and standard deviation) and gives as output a Gaussian kernel matrix. Display 3 instances of the kernel with different parameters.  \n",
    "\n",
    "```Hints```:\n",
    "- Show that kernel elements sum up to 1.\n",
    "- You may want to use functions ```np.arange```, ```np.linspace``` and/or ```np.meshgrid``` for creating the regular grid onto which to compute the Gaussian filter weights.\n",
    "- use the 'None' or 'Nearest' interpolation options of imshow to display the kernel images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussianKernel(hs,sig):\n",
    "    u= np.linspace(-hs,hs,2*hs+1);\n",
    "    v= np.linspace(-hs,hs,2*hs+1);\n",
    "    uu,vv =np.meshgrid(u,v);  \n",
    "    kernel=(1/(2*np.pi*sig**2))*np.exp(-(uu**2+vv**2)/(2*sig**2));\n",
    "    kernel/=np.sum(kernel);\n",
    "    plt.imshow(kernel, interpolation='Nearest');\n",
    "    return kernel\n",
    "\n",
    "kernel = gaussianKernel(100,20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width=8\n",
    "height=3\n",
    "plt.rcParams['figure.figsize'] = [width, height]\n",
    "\n",
    "#creating and showing three mean kernels of different sizes\n",
    "k = 1\n",
    "for hs, sig in [(1, 1),(3, 2), (11, 1)]:\n",
    "    plt.subplot(1,3,k)\n",
    "    kernel = gaussianKernel(hs, sig)\n",
    "    plt.imshow(kernel, vmin=0, vmax=0.2)\n",
    "    plt.title('Gaussian')\n",
    "    k+=1\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Smoothing for reducing aliasing\n",
    "\n",
    "Apply the ```Gaussian``` filter from the previous exercise to 1 image from the ```smooth``` folder.Â \n",
    "\n",
    "Use the scipy convolution function\n",
    "```python\n",
    "ndimage.convolve(im,kernel)\n",
    "```\n",
    "\n",
    "```Hint```: Convert the images to grayscale before filtering. you can use your own ```rgb2gray``` function or read the images with the ```io.imread``` function with mode ```as_gray=True```. \n",
    "\n",
    "For the chosen image demonstrate the interest of smoothing prior to subsampling to reduce aliasing (show results for 3 sampling rates: 1/2, 1/4, 1/8). Comment on the how to choose the appropriate kernel sizes in each case\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBDIR = os.path.join(IMDIR, \"smooth\")\n",
    "f = os.path.join(SUBDIR, \"grass.jpg\")\n",
    "\n",
    "width=15\n",
    "height=5\n",
    "\n",
    "hs = 3\n",
    "sigma = 0.5\n",
    "\n",
    "im = io.imread(f, as_gray=True)\n",
    "im = im.astype(float)\n",
    "im = resize(im,(100,100))    \n",
    "kernel = gaussianKernel(hs,sigma)\n",
    "im_filtered_scipy = ndimage.convolve(im,kernel)\n",
    "\n",
    "fig=plt.figure(figsize=(width, height))\n",
    "\n",
    "plt.subplot(1,2,1)        \n",
    "plt.imshow(im, cmap = 'gray')\n",
    "plt.title('Gaussian original')\n",
    "                \n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(im_filtered_scipy, cmap = 'gray')\n",
    "plt.title('Gaussian scipy conv')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsampling(im,factor):\n",
    "    im_sub=im[::factor,::factor]\n",
    "    return im_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hs = 3\n",
    "sigma = 2\n",
    "\n",
    "im = io.imread(f, as_gray=True)\n",
    "im = im.astype(float)\n",
    "im = resize(im,(100,100))   \n",
    "\n",
    "kernel = gaussianKernel(hs,sigma)\n",
    "im_filtered_scipy = ndimage.convolve(im,kernel)\n",
    "\n",
    "fig=plt.figure(figsize=(width, height))\n",
    "\n",
    "plt.subplot(2,4,1)        \n",
    "plt.imshow(im, cmap = 'gray')\n",
    "plt.title('Image original size')\n",
    "\n",
    "plt.subplot(2,4,2)        \n",
    "plt.imshow(subsampling(im,2), cmap = 'gray')\n",
    "plt.title('Image original resize 1/2')\n",
    "\n",
    "plt.subplot(2,4,3)        \n",
    "plt.imshow(subsampling(im,4), cmap = 'gray')\n",
    "plt.title('Image original resize 1/4')\n",
    "\n",
    "plt.subplot(2,4,4)        \n",
    "plt.imshow(subsampling(im,8), cmap = 'gray')\n",
    "plt.title('Image original resize 1/8')\n",
    "\n",
    "plt.subplot(2,4,5)        \n",
    "plt.imshow(im_filtered_scipy, cmap = 'gray')\n",
    "plt.title('Gaussian original')\n",
    "\n",
    "plt.subplot(2,4,6)        \n",
    "plt.imshow(subsampling(im_filtered_scipy,2), cmap = 'gray')\n",
    "plt.title('Gaussian resize 1/2')\n",
    "\n",
    "plt.subplot(2,4,7)        \n",
    "plt.imshow(subsampling(im_filtered_scipy,4), cmap = 'gray')\n",
    "plt.title('Gaussian resize 1/4')\n",
    "\n",
    "plt.subplot(2,4,8)        \n",
    "plt.imshow(subsampling(im_filtered_scipy,8), cmap = 'gray')\n",
    "plt.title('Gaussian resize 1/8')\n",
    "\n",
    "plt.tight_layout()       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Filtering with your own Convolution\n",
    "**a)** Repeat the smoothing above with your own implementation of the ```convolution``` function. The function should receive as input an image and a filter kernel (matrix of weights) and return the filtered image. Compare your results with those from the scikit in-built function.\n",
    "\n",
    "**b)** Apply to 3  images from the ``smooth`` folder a Gaussian filter with fixed parameters and display side by side your results vs. those of the in-built function to check your implementation is correct. Clearly state on the title of the image which version of the convolution function is being used.\n",
    "\n",
    "```Hint```: you may implement the convolution with or without loops or writing the convolution as a matrix multiplication (see http://cs231n.github.io/convolutional-networks/)\n",
    "\n",
    "**c)** **Write down your findings**, notably the reasons for any possible difference with the in-built implementation. \n",
    "\n",
    "**d)** Why and how can the convolution can be written as a matrix multiplication?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myConvolution(im,kernel):\n",
    "    im_ref=im.copy\n",
    "    hs=int((kernel.shape[1]-1)/2)\n",
    "    x,y=im.shape;\n",
    "    im_filtered=np.zeros((x,y));\n",
    "    im_ref=np.pad(im,hs)\n",
    "    for i in range(x):\n",
    "        for j in range(y):\n",
    "            im_filtered[i,j]=0\n",
    "            for u in range(-hs,hs):\n",
    "                for v in range(-hs,hs):\n",
    "                    im_filtered[i,j]+= (kernel[u+hs,v+hs]*im_ref[i+hs-u,j+hs-v])\n",
    "    return im_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBDIR = os.path.join(IMDIR, \"smooth\")\n",
    "f = os.path.join(SUBDIR, \"grass.jpg\")\n",
    "\n",
    "width=20\n",
    "height=20\n",
    "\n",
    "hs = 3\n",
    "sigma = 2\n",
    "\n",
    "im = io.imread(f, as_gray=True)\n",
    "im = im.astype(float)\n",
    "im = resize(im,(100,100))   \n",
    "\n",
    "kernel = gaussianKernel(hs,sigma)\n",
    "im_filtered_scipy = ndimage.convolve(im,kernel)\n",
    "\n",
    "fig=plt.figure(figsize=(width, height))\n",
    "\n",
    "im_filtered=myConvolution(im,kernel)\n",
    "\n",
    "plt.subplot(1,4,1)\n",
    "plt.imshow(im, cmap = 'gray')\n",
    "plt.title('Original')\n",
    "\n",
    "plt.subplot(1,4,2)\n",
    "plt.imshow(im_filtered, cmap = 'gray')\n",
    "plt.title('Gaussian own conv')\n",
    "\n",
    "plt.subplot(1,4,3)\n",
    "plt.imshow(im_filtered_scipy, cmap = 'gray')\n",
    "plt.title('Gaussian scipy conv')\n",
    "\n",
    "plt.subplot(1,4,4)\n",
    "plt.imshow(im_filtered_scipy-im_filtered, cmap = 'gray')\n",
    "plt.title('Gaussian Difference')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque les diffÃ©rences suivantes entre les 2 fonctions de convolution :\n",
    "\n",
    "* Notre implÃ©mentation a recourt Ã  du zero padding mais par dÃ©faut la fonction built-in utilise un padding mirroir\n",
    "* La fonction python est mieux implementer que la notre, il n'y a pas d'effet de bords\n",
    "* python optimise mieux les calculs\n",
    "* En effet la convolution peut Ãªtre implementÃ©e sous forme d'un calcul matriciel plutÃ´t qu'une suite de for"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Derivative filters\n",
    "\n",
    "2.1 Create a function that generates the 3 kernels required to compute \n",
    "- the *image gradient* in the x and in the y direction, \n",
    "- the *image Laplacian* (the output should be 3 kernel matrices).\n",
    "\n",
    "2.2 For each kernel, show the behaviour of using it to convolve  images from the ``gradient`` folder with each kernel from 2.1. Show the resultant gradients in each direction, the gradient magnitude, and the laplacian.\n",
    "\n",
    "2.3. **Write down your remarks for each image**: (e.g. why are some edges visible and others not?, when is it useful to use a derivative filter, what are the limitations? etc...)\n",
    "\n",
    "2.4 **Image enhancement**\n",
    "\n",
    "Use one of the contour enhancing methods seen in the lecture (unsharp masking, highboost filtering or laplacian enhancement) to \"sharpen\" one of the images in the ``enhance`` folder. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateGradientKernel():\n",
    "    kernel = np.array([[1,0,-1], [2,0,-2], [1,0,-1]])\n",
    "    return (kernel, kernel.T)\n",
    "\n",
    "def generateLaplacianKernel():\n",
    "    return np.array([[0,1,0], [1,-4,1], [0,1,0]])\n",
    "\n",
    "def gradient_x(im):\n",
    "    kernel, _ = generateGradientKernel()\n",
    "    return ndimage.convolve(im, kernel)\n",
    "\n",
    "def gradient_y(im):\n",
    "    _, kernel = generateGradientKernel()\n",
    "    return ndimage.convolve(im, kernel)\n",
    "\n",
    "def gradient_norm(im):\n",
    "    return np.sqrt(gradient_x(im)**2 + gradient_y(im)**2)\n",
    "\n",
    "def laplacian(im):\n",
    "    kernel = generateLaplacianKernel()\n",
    "    return  ndimage.convolve(im, kernel)\n",
    "\n",
    "width=20\n",
    "height=20\n",
    "plt.rcParams['figure.figsize'] = [width, height]\n",
    "            \n",
    "fig=plt.figure()\n",
    "\n",
    "SUBDIR = os.path.join(IMDIR, \"enhance\")\n",
    "\n",
    "im_counter = 1\n",
    "for root, dirnames, filenames in os.walk(SUBDIR):\n",
    "    for filename in filenames:\n",
    "        f = os.path.join(root, filename)\n",
    "        \n",
    "        if f.endswith(('.png', '.jpg', '.jpeg','.JPG', '.tif', '.gif')):\n",
    "            im = io.imread(f,as_gray=True)\n",
    "            im = resize(im,(100,100),mode='constant')\n",
    "                \n",
    "            plt.subplot(8,5,im_counter)\n",
    "            plt.imshow(im, cmap='gray')\n",
    "            plt.title(filename)\n",
    "            plt.axis('off')\n",
    "            \n",
    "            plt.subplot(8,5, im_counter+1)\n",
    "            plt.imshow(gradient_x(im), cmap='gray')\n",
    "            plt.title('gradient_x')\n",
    "            plt.axis('off')\n",
    "            \n",
    "            plt.subplot(8,5, im_counter+2)\n",
    "            plt.imshow(gradient_y(im), cmap='gray')\n",
    "            plt.title('gradient_y')\n",
    "            plt.axis('off')\n",
    "            \n",
    "            plt.subplot(8,5, im_counter+3)\n",
    "            plt.imshow(gradient_norm(im), cmap='gray')\n",
    "            plt.title('gradient_norm')\n",
    "            plt.axis('off')\n",
    "            \n",
    "            plt.subplot(8,5, im_counter+4)\n",
    "            plt.imshow(laplacian(im), cmap='gray')\n",
    "            plt.title('laplacian')\n",
    "            plt.axis('off')           \n",
    "            \n",
    "            im_counter += 5 \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remarques :\n",
    "\n",
    "* pour chaque image, les images obtenues par le calcul de norme du gradient et du laplacian sont similaires et approximent le contour de l'image originale\n",
    "* les composantes du gradient permettent d'observer la vitesse de changement de couleurs dans l'image selon les axes x et y\n",
    "* comme on peut le voir pour l'image `moon-blurred` par exemple, le gradient est assez sensible aux dÃ©tails de l'image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def laplacianEnhance(im,c):\n",
    "    kernelL =generateLaplacianKernel()\n",
    "    laplaceImg=ndimage.convolve(im,kernelL)\n",
    "    im_sharp = im+c*laplaceImg\n",
    "    return im_sharp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(im):\n",
    "    return 255 / (np.max(im) - np.min(im)) * (im - np.min(im))\n",
    "\n",
    "SUBDIR = os.path.join(IMDIR, \"enhance\")\n",
    "f = os.path.join(SUBDIR, \"moon-blurred.tif\")\n",
    "\n",
    "width=20\n",
    "height=20\n",
    "\n",
    "hs = 3\n",
    "sigma = 2\n",
    "\n",
    "im = io.imread(f, as_gray=True)\n",
    "im = im.astype(float)\n",
    "#im = resize(im,(100,100))\n",
    "\n",
    "im_enhance=laplacianEnhance(im,-1)\n",
    "im_enhance_normalized = (im_enhance-np.min(im_enhance))*((np.max(im)-np.min(im))/(np.max(im_enhance)-np.min(im_enhance)))\n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(im, cmap = 'gray')\n",
    "plt.title('Original image')\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(im_enhance, cmap = 'gray')\n",
    "plt.title('Enhanced image')\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(im_enhance_normalized, cmap = 'gray')\n",
    "plt.title('Enhanced image normalized')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Bilateral Filter\n",
    "\n",
    "Implement your own version of the ``bilateral`` filter and compare its results vs. scikit ``denoise_bilateral`` function. Show results one image for the ``denoising `` folder for different values of the spatial and color kernels, and for different iterations\n",
    "\n",
    "__BONUS__: Combine iterative bilateral filter with unsharp masking to create rotorized-like images. See an example from the ``cartoonize`` folder such as the ones used in \"Scanner Darkly\", \"Undonne\", and others)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_kernel_depend(im_ref,i,j,u,v,sig2,hs):\n",
    "    kernel = np.zeros((2*hs+1,2*hs+1));\n",
    "    for u in range(-hs,hs):\n",
    "        for v in range(-hs,hs):\n",
    "            kernel[u,v] = (1/(2*np.pi*sig2**2))*np.exp(-1*(im_ref[i+u,j+v]-im_ref[i,j])**2/(2*sig2**2))\n",
    "    return kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bilateral(im, hs, sig1, sig2):\n",
    "    im_ref=im.copy\n",
    "    x,y=im.shape;\n",
    "    im_filtered=np.zeros((x,y));\n",
    "    im_ref=np.pad(im,hs)\n",
    "    kernel_gauss = gaussianKernel(hs,sig1)\n",
    "    for i in range(x):\n",
    "        for j in range(y):\n",
    "            im_filtered[i,j]=0\n",
    "            for u in range(-hs,hs):\n",
    "                for v in range(-hs,hs):\n",
    "                    kernel_content= compute_kernel_depend(im_ref,i,j,u,v,sig2,hs)\n",
    "                    kernel_content/=np.sum(kernel_content);\n",
    "                    kernel = kernel_gauss*kernel_content\n",
    "                    im_filtered[i,j]+= (kernel[u+hs,v+hs]*im_ref[i+hs-u,j+hs-v])\n",
    "    return im_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.restoration import denoise_bilateral\n",
    "\n",
    "width=50\n",
    "height=50\n",
    "\n",
    "\n",
    "SUBDIR = os.path.join(IMDIR, \"denoise\")\n",
    "f = os.path.join(SUBDIR, \"taj.jpg\")\n",
    "\n",
    "im = io.imread(f, as_gray=True)\n",
    "im = im.astype(float)\n",
    "fig=plt.figure(figsize=(width, height))\n",
    "im = resize(im,(100,100))\n",
    "\n",
    "my_im_denoised = bilateral(im,3,0.05,15)\n",
    "im_denoised = denoise_bilateral(im, sigma_color=0.05, sigma_spatial=15)\n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(im, cmap='gray')\n",
    "plt.title('original')\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(im_denoised, cmap='gray')\n",
    "plt.title('denoise scikit')\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(my_im_denoised, cmap='gray')\n",
    "plt.title('homemade bilateral')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Find Waldo (Charlie): template matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use patch-wise Normalized Cross Correlation (NCC) to automatically find Waldo (Charlie) in an image. To this end, look for the template image (``charlie-template``) inside ``marche-crop`` or the ``marche`` images. As the process can be long start with the cropped version, you might also find it useful to create a separate notebook for this task only. Evaluate the NCC expression from the slides (non-local means) to compare the template with every location in the target image, store the results and retrieve the location with the highest NCC score. Draw this location on the target image.\n",
    "\n",
    "**Describe the process assumptions and limitations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as patches\n",
    "\n",
    "SUBDIR = os.path.join(IMDIR, \"charlie\")\n",
    "f1 = os.path.join(SUBDIR, \"marche-crop.png\")\n",
    "f2 = os.path.join(SUBDIR, \"charlie-template.jpeg\")\n",
    "\n",
    "im = io.imread(f1, as_gray=True)\n",
    "template = io.imread(f2, as_gray=True)\n",
    "# on rescale l'image pour reduire les calculs\n",
    "im = rescale(im, 0.3)\n",
    "template = rescale(template, 0.3)\n",
    "\n",
    "def findTemplate(im, template):\n",
    "    h_target, w_target = im.shape\n",
    "    h_template, w_template = template.shape\n",
    "    \n",
    "    max_ncc = 0\n",
    "    template_mean = np.sum(template) / (h_template * w_template)\n",
    "    for u in range(h_target - h_template):\n",
    "        for v in range(w_target - w_template):\n",
    "            im_mean = sum(im[u:u+h_template, v+w_template]) / (h_template * w_template)\n",
    "                        \n",
    "            num = den_1 = den_2 = 0\n",
    "            for i in range(h_template):\n",
    "                for j in range(w_template):\n",
    "                    num += (im[u+i, v+j] - im_mean) * (template[i, j] - template_mean)\n",
    "                    den_1 += (im[u+i, v+j] - im_mean) ** 2\n",
    "                    den_2 += (template[i, j] - template_mean) ** 2\n",
    "            \n",
    "            ncc = num / np.sqrt(den_1 * den_2)\n",
    "            \n",
    "            if ncc > max_ncc:\n",
    "                res = (v, u)\n",
    "                max_ncc = ncc\n",
    "                \n",
    "    return res\n",
    "\n",
    "pos = findTemplate(im, template)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(im, cmap='gray')\n",
    "rect = patches.Rectangle(pos, template.shape[1], template.shape[0], linewidth=2, edgecolor='r', facecolor='none')\n",
    "ax.add_patch(rect)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque que :\n",
    "\n",
    "* Cette mÃ©thode necessite que la taille du template soit Ã©gale Ã  celle du motif recherchÃ© dans l'image\n",
    "* Le temps de calcul est trÃ¨s important Ã©tant donnÃ© une complexitÃ© en O(taille du template x taille de l'image)\n",
    "* Cette mÃ©thode fonctionne uniquement pour les images en niveaux de gris"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
